###
##
## The 3 variables controlling the flow are:
##  a) messageConsumerThreads: how many threads are reading from rabbit, and computing mutations
##  b) batchSize: how large a batch from a) needs to be before handed over to the flush thread
##  c) batchFlushThreads: how many threads are flushing to HBase (increments like many concurrent)
## Be aware that b) and c) dictate the memory requirements
##
## This is in incrementing cube, which means that HBase column increment is used.  Testing on HBase 
## suggests large concurrency increases throughput significantly, so a large number of flushing threads
## are used.  This lends itself well to large batching (up to 300 mutations per record).  The consuming
## threads are tuned to saturate the flushing threads, by monitoring the backOffMeter and setting to 
## a level high enough but ensuring we don't go into backoff mode.
####
hbaseConfig: /home/crap/config/hbase-site.xml
ganglia:
  gangliaHost: b5g2.gbif.org
  gangliaPort: 8649
messaging:
  host: mq.gbif.org
  virtualHost: /crawler/dev
  username: metrics
  password: metrics
queueName: metrics_occurrence_cube
cubeTable: crawler_occurrence_cube
columnFamily: dc
messageConsumerThreads: 1
batchSize: 1000000
batchFlushThreads: 100
